2.3.2 Distance-Based Prospect Selection (New)
In the current approach, prospect selection relies on distance rather than similarity. Specifically, each cluster produced by the K-Means algorithm has a maximum distance (or â€œradiusâ€), which is the farthest distance a PWM client in that cluster is from the clusterâ€™s centroid. Any prospect whose distance to that cluster centroid is less than or equal to this maximum distance is considered close enough to be a potential PWM lead.

Why Distance?

We measure the Euclidean distance from a prospectâ€™s scaled feature vector to each cluster centroid.

If the prospectâ€™s distance is within at least one clusterâ€™s maximum distance, we include that prospect in our final list.

Outcome

This ensures that if a prospectâ€™s position in the scaled feature space is similar to the most distant existing PWM client in that cluster, they qualify. Prospects lying outside all cluster radii are excluded.

2.3.3 Calculating Similarity Score (Additional Reference)
Although the pipeline no longer uses cosine similarity to decide which prospects to include, we still compute a similarity score as an additional reference. This similarity score indicates how closely a prospectâ€™s feature vector aligns with each clusterâ€™s centroid.

Use Case: Business teams can still look at the similarity score to see which cluster a prospect fits best, or compare multiple prospects on a single scale.

Cross-Join and Formula: We cross-join prospective clients (filtered to exclude existing PWM clients) with the pre-computed cluster centroids and calculate the score via:

CosineÂ Similarity
=
ğ´
â‹…
ğµ
âˆ¥
ğ´
âˆ¥
Â 
âˆ¥
ğµ
âˆ¥
CosineÂ Similarity= 
âˆ¥Aâˆ¥Â âˆ¥Bâˆ¥
Aâ‹…B
â€‹
 
where 
ğ´
A is the feature vector of a prospect, and 
ğµ
B is the centroid of a cluster. The higher the similarity score, the more closely the prospect matches that clusterâ€™s overall profile.

While distance ultimately determines inclusion in the final PWM prospect list, similarity remains a helpful indicator of how strongly a prospect aligns with the typical traits of that cluster.

# **Automated Private Wealth Prospecting Pipeline**

## **1. Overview**

This pipeline aims to **find new leads** for Private Wealth Management (PWM). It does so by:

1. **Regularly picking** the **best features** (columns) each month, so it **adapts** to changes in customer behavior.  
2. **Grouping** existing PWM clients with a clustering approach that **doesnâ€™t overly exclude** potential leads.  
3. **Highlighting** specific reasons why a household is similar to PWM clients, so business teams can easily see the **key factors**.

Ultimately, this ensures the pipeline **keeps up** with changing patterns and **explains** each householdâ€™s inclusion.

---

## **2. Monthly Feature Selection**

### **2.1 Why We Select Features Dynamically**

- **Data Shifts**: Over time, new products come out, or clientsâ€™ usage patterns change. Columns that used to be key might lose relevance, and new columns might become more important.  
- **Prevent Staleness**: If we **never** refreshed which columns we focus on, weâ€™d risk â€œfeature drift,â€ where the pipeline relies on outdated factors.  
- **Automatic Updates**: By **re-checking** the best columns each month, the pipeline always uses the **freshest** indicators of PWM-like behavior.

### **2.2 How We Do It with a Random Forest**

- **Basic Idea**: A â€œrandom forestâ€ model looks at which columns best separate **existing PWM** clients from ordinary **consumers**.  
- **Ranking Columns**: After training, it gives each column an **importance score**â€”like how strongly â€œbalance growthâ€ or â€œcredit usageâ€ helps identify PWM.  
- **Top Columns**: We **sort** columns by importance and pick the top (say 20). These become the focus for clustering and analysis that month.  
- **Outcome**: If â€œonline transfersâ€ suddenly becomes a big differentiator, it rises in the ranking, and older, less useful columns drop off.

---

## **3. Grouping Existing PWM Clients (Clustering)**

### **3.1 Why We Need Clusters**

- **Varied Patterns**: Not all PWM clients look the same. Some might have huge balances, others might have multiple investment products, etc.  
- **Making Groups**: By clustering them, we find **natural subgroups** so we can measure a potential leadâ€™s closeness to each subgroup.

### **3.2 How We Scale and Cluster**

- **Scaling**: We use something called **MinMax scaling**, which shrinks each chosen column into a range **from 0 to 1**. This **prevents** one extreme column (like an enormous balance) from overshadowing others.  
- **K-Means**: Next, we apply **K-Means** to these scaled columns, splitting PWM clients into, say, 5 or 10 subgroups. Each subgroup has a **center** in this scaled space.  
- **Max Distance**: For each group, we measure the **farthest** PWM client from that center. That distance is our â€œcluster radius.â€ If youâ€™re within that radius, youâ€™re considered close enough to that group.

---

## **4. Finding New Prospects**

### **4.1 Assigning a Prospect to a Cluster**

- **Same Scaling**: A new householdâ€™s data is shrunk to the same 0â€“1 range used for clustering.  
- **Compare Distance**: We calculate how far they are from each groupâ€™s center. The **closest** center is that prospectâ€™s best match.  
- **Include or Exclude**: If that distance is **less than** the groupâ€™s radius, we **include** the prospect; otherwise, theyâ€™re too far.

### **4.2 Why Distance Filtering Works**

- **True Similarity**: If youâ€™re **closer** than the farthest actual PWM client, you likely share the relevant traits (high balances, certain product usage, etc.).  
- **Broad Enough**: The radius ensures we donâ€™t set an **artificially small** cutoffâ€”if real PWM are that far, itâ€™s valid to include prospects that far as well.

---

## **5. Explaining Each Cluster via â€œ1 vs. Allâ€**

### **5.1 Why Explain Clusters Separately**

- **Different Subgroups**: Each cluster can be **quite unique**â€”some revolve around large deposit usage, others around big credit products. A single explanation for all PWM wouldnâ€™t capture these nuances.

### **5.2 How â€œ1 vs. Allâ€ Works**

- **One Cluster Is â€œPositiveâ€**: Take cluster A and label its PWM as **1** (the positives).  
- **All Other Clusters Are â€œNegativeâ€**: PWM in clusters B, C, etc. are **0**.  
- **Train a Small Model**: This small model sees which **chosen columns** (from the monthly selection) best distinguish cluster A from every other cluster.  
- **Top Features per Cluster**: We end up with, say, 5 key columns that define cluster Aâ€™s identity. Then we do the same for cluster B, and so on.

### **5.3 Why This Matters**

- **Cluster Identity**: We can quickly say, â€œCluster A is typically about big money market usage + multiple credit products,â€ while cluster B might revolve around â€œhigh net worth segment + advanced investment accounts.â€  
- **Better Explanation**: When a new household falls into cluster A, we know it matched **that** clusterâ€™s main featuresâ€”so we can easily highlight them in an insight statement or note.  

---

## **6. Non-Technical Summary of the Whole Flow**

1. **Pick the Best Columns** each month with a **random forest** (this avoids stale or less predictive data).  
2. **Group** existing PWM by **K-Means** on those columns. Each group has a **radius** based on the farthest PWM in that group.  
3. **Assign** new households by measuring distance to each group. If theyâ€™re within a groupâ€™s radius, we say **theyâ€™re included**.  
4. **Define** each groupâ€™s main traits using a **1 vs. all** approach (one cluster vs. the rest of PWM).  
5. **Result**: We get a new set of prospects monthly who match current PWM behaviors, plus a short explanation of why each cluster is special.

---

## **7. Why This Approach is Effective**

- **Adapts Monthly**: The feature selection step ensures we never rely on outdated patterns.  
- **Broad, Balanced Groups**: MinMax scaling avoids overshadowing smaller columns, letting us fairly measure all relevant traits.  
- **Distance Filtering**: Only prospects who truly resemble at least one PWM group get included, limiting false positives.  
- **Clear â€œ1 vs. Allâ€**: Each clusterâ€™s defining features are easy to see and communicate, bridging the gap between data science and business.

---

## **8. Further Notes**

- **Adjusting the Number of Clusters**: Fewer clusters â†’ bigger groups, more inclusive radius. More clusters â†’ narrower, more specific subgroups.  
- **Changing the Distance**: If you want more leads, you could allow a bit more distance than the farthest PWM clientâ€”like a 10% buffer.  
- **Going Deeper on Insights**: If you want numeric or range details, you can still store them. But many teams prefer a simpler approach that just states the top reasons.  

With these steps, your organization can **consistently** identify potential PWM leads, **explain** how they match existing clients, and **stay relevant** as new data emerges.
