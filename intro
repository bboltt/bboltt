Below are the rates for recent monthly runs:

2024-03-31: ~85.7% capture rate

2024-04-30: ~83.3% capture rate

2024-06-30: ~76.0% capture rate

2024-05-31: ~71.1% capture rate
---

### **2.3.6 Performance Evaluation (Refined)**

**Purpose**  
We measure how many **actual PWM conversions** (i.e., consumers who truly ended up with PWM status) were **successfully flagged** as prospects by this pipeline. We define **conversion capture rate** as:

\[
  \text{Conversion Capture Rate} 
  = \frac{\text{Number of valid PWM conversions that were also selected as prospects}}{\text{Total number of valid PWM conversions}}
\]

---

**1) Identifying Potential Conversions**  
- We first pinpoint a group of **target consumers**—for example, those meeting certain conditions (e.g., having assets above a threshold) who currently do **not** have a PWM relationship.  
- Over the next **6 months**, we track which of these target consumers actually establish a **new** PWM relationship. Those are **valid conversions** (the “ground truth”).

**2) Checking the Pipeline’s Predictions**  
- Separately, on the **score date** (e.g., end of March), the pipeline selects a subset of consumers as **prospects** using our distance-based approach.  
- We then see how many of the **actual converters** (from step 1) were also **predicted** as prospects. The overlap is the **captured conversions**.

**3) Capture Rate**  
- The ratio of “captured conversions” to “all actual conversions” is our main success measure. For example, if 100 consumers truly became PWM within 6 months, and 85 of them were in our prospect list, our capture rate is 85%.  
- A **higher** capture rate means we found more real converters in our leads; a **lower** rate means we missed too many actual PWM joiners.

---

**Interpretation**  
- **Why We Want a High Capture Rate**: If the model’s chosen leads cover **most** of the consumers who *actually* became PWM, it indicates we’re effectively identifying households with genuine PWM potential.  
- **Assumption**: We treat all unselected consumers as having *similar potential* to those who converted. If a significant portion of actual converters were never flagged, it suggests we might be missing out on real opportunities.

---

**Example**  
- Suppose in March we identified 500 target consumers (no PWM status yet). Six months later, 70 of them **did** open PWM relationships. Our pipeline had predicted 60 of those 70 as prospects.  
  - **Capture Rate**: \(60/70 = 85.7\%\).  
  - This implies our pipeline “caught” 85.7% of the actual new PWM clients—an encouraging sign that our distance-based approach effectively spots households with near-future PWM potential.

By **periodically reviewing** the capture rate (and adjusting thresholds or cluster parameters if needed), we can ensure our pipeline consistently targets the **majority** of real PWM conversions.

## **1. Overview**

This pipeline aims to **find new leads** for Private Wealth Management (PWM). It does so by:

1. **Regularly picking** the **best features** (columns) each month, so it **adapts** to changes in customer behavior.  
2. **Grouping** existing PWM clients with a clustering approach that **doesn’t overly exclude** potential leads.  
3. **Highlighting** specific reasons why a household is similar to PWM clients, so business teams can easily see the **key factors**.

Ultimately, this ensures the pipeline **keeps up** with changing patterns and **explains** each household’s inclusion.

---

## **2. Monthly Feature Selection**

### **2.1 Why We Select Features Dynamically**

- **Data Shifts**: Over time, new products come out, or clients’ usage patterns change. Columns that used to be key might lose relevance, and new columns might become more important.  
- **Prevent Staleness**: If we **never** refreshed which columns we focus on, we’d risk “feature drift,” where the pipeline relies on outdated factors.  
- **Automatic Updates**: By **re-checking** the best columns each month, the pipeline always uses the **freshest** indicators of PWM-like behavior.

### **2.2 How We Do It with a Random Forest**

- **Basic Idea**: A “random forest” model looks at which columns best separate **existing PWM** clients from ordinary **consumers**.  
- **Ranking Columns**: After training, it gives each column an **importance score**—like how strongly “balance growth” or “credit usage” helps identify PWM.  
- **Top Columns**: We **sort** columns by importance and pick the top (say 20). These become the focus for clustering and analysis that month.  
- **Outcome**: If “online transfers” suddenly becomes a big differentiator, it rises in the ranking, and older, less useful columns drop off.

---

## **3. Grouping Existing PWM Clients (Clustering)**

### **3.1 Why We Need Clusters**

- **Varied Patterns**: Not all PWM clients look the same. Some might have huge balances, others might have multiple investment products, etc.  
- **Making Groups**: By clustering them, we find **natural subgroups** so we can measure a potential lead’s closeness to each subgroup.

### **3.2 How We Scale and Cluster**

- **Scaling**: We use something called **MinMax scaling**, which shrinks each chosen column into a range **from 0 to 1**. This **prevents** one extreme column (like an enormous balance) from overshadowing others.  
- **K-Means**: Next, we apply **K-Means** to these scaled columns, splitting PWM clients into, say, 5 or 10 subgroups. Each subgroup has a **center** in this scaled space.  
- **Max Distance**: For each group, we measure the **farthest** PWM client from that center. That distance is our “cluster radius.” If you’re within that radius, you’re considered close enough to that group.

---

## **4. Finding New Prospects**

### **4.1 Assigning a Prospect to a Cluster**

- **Same Scaling**: A new household’s data is shrunk to the same 0–1 range used for clustering.  
- **Compare Distance**: We calculate how far they are from each group’s center. The **closest** center is that prospect’s best match.  
- **Include or Exclude**: If that distance is **less than** the group’s radius, we **include** the prospect; otherwise, they’re too far.

### **4.2 Why Distance Filtering Works**

- **True Similarity**: If you’re **closer** than the farthest actual PWM client, you likely share the relevant traits (high balances, certain product usage, etc.).  
- **Broad Enough**: The radius ensures we don’t set an **artificially small** cutoff—if real PWM are that far, it’s valid to include prospects that far as well.

---

## **5. Explaining Each Cluster via “1 vs. All”**

### **5.1 Why Explain Clusters Separately**

- **Different Subgroups**: Each cluster can be **quite unique**—some revolve around large deposit usage, others around big credit products. A single explanation for all PWM wouldn’t capture these nuances.

### **5.2 How “1 vs. All” Works**

- **One Cluster Is “Positive”**: Take cluster A and label its PWM as **1** (the positives).  
- **All Other Clusters Are “Negative”**: PWM in clusters B, C, etc. are **0**.  
- **Train a Small Model**: This small model sees which **chosen columns** (from the monthly selection) best distinguish cluster A from every other cluster.  
- **Top Features per Cluster**: We end up with, say, 5 key columns that define cluster A’s identity. Then we do the same for cluster B, and so on.

### **5.3 Why This Matters**

- **Cluster Identity**: We can quickly say, “Cluster A is typically about big money market usage + multiple credit products,” while cluster B might revolve around “high net worth segment + advanced investment accounts.”  
- **Better Explanation**: When a new household falls into cluster A, we know it matched **that** cluster’s main features—so we can easily highlight them in an insight statement or note.  

---

## **6. Non-Technical Summary of the Whole Flow**

1. **Pick the Best Columns** each month with a **random forest** (this avoids stale or less predictive data).  
2. **Group** existing PWM by **K-Means** on those columns. Each group has a **radius** based on the farthest PWM in that group.  
3. **Assign** new households by measuring distance to each group. If they’re within a group’s radius, we say **they’re included**.  
4. **Define** each group’s main traits using a **1 vs. all** approach (one cluster vs. the rest of PWM).  
5. **Result**: We get a new set of prospects monthly who match current PWM behaviors, plus a short explanation of why each cluster is special.

---

## **7. Why This Approach is Effective**

- **Adapts Monthly**: The feature selection step ensures we never rely on outdated patterns.  
- **Broad, Balanced Groups**: MinMax scaling avoids overshadowing smaller columns, letting us fairly measure all relevant traits.  
- **Distance Filtering**: Only prospects who truly resemble at least one PWM group get included, limiting false positives.  
- **Clear “1 vs. All”**: Each cluster’s defining features are easy to see and communicate, bridging the gap between data science and business.

---

## **8. Further Notes**

- **Adjusting the Number of Clusters**: Fewer clusters → bigger groups, more inclusive radius. More clusters → narrower, more specific subgroups.  
- **Changing the Distance**: If you want more leads, you could allow a bit more distance than the farthest PWM client—like a 10% buffer.  
- **Going Deeper on Insights**: If you want numeric or range details, you can still store them. But many teams prefer a simpler approach that just states the top reasons.  

With these steps, your organization can **consistently** identify potential PWM leads, **explain** how they match existing clients, and **stay relevant** as new data emerges.
