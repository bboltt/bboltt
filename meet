I’d like to share a bit about myself. I’m passionate about snowboarding and I’m a little jealous of Srsalan because he lives in Denver, where the snow is amazing! Here, the snow isn’t as good, but fortunately it only takes me about an hour and a half to reach the nearest resorts, so I still get to enjoy it regularly.

I also love working out. I’ve been going to the gym at least two or three times a week for almost ten years now. In addition, I practice Brazilian Jiu-Jitsu, which has been a great way to stay active and challenge myself.

Outside of work, most of my time is spent with my two kids. We do almost everything together—snowboarding, Jiu-Jitsu, and playing soccer. They keep me busy and bring a lot of joy to my life.


“I recently worked on an Inclearing Fraud Detection project at a financial institution, where we aimed to identify and flag fraudulent checks in the inclearing process. We drew data from multiple sources, including:

A base inclearing transactions table (amount, date/time, account details)

Mitek check‐image analysis (to detect physical alterations)

Device login logs (highlighting unusual access patterns)

Call center interactions (capturing high‐risk call reasons or escalations)

Because fraud was extremely rare—often under one percent of checks—we first tackled class imbalance by upsampling fraudulent rows, giving the model more examples of minority‐class patterns. However, we encountered a specific challenge with large‐value checks: the dataset had very few fraud cases at high amounts, so the model tended to learn that checks above a certain threshold were “safe.”

To address this, we introduced a targeted bucketing strategy on the check amount feature. Rather than letting the model split purely on continuous values—where it might place a single cutoff around $2,000 or $5,000—we transformed “amount” into a few carefully chosen bins:

$0–$1,000: Fine‐grained intervals of $50 each, because low‐value fraud is more common.

$1,000–$2,000: $100 increments for moderate‐value checks.

> $2,000: A single large bucket forcing the model to rely on other signals (e.g., account or Mitek flags) for these high amounts.

This approach helped avoid a simplistic threshold split in the large‐value range, which had few fraud examples. By placing all big checks in one category, the Gradient Boosted Trees model had to look at other features to identify high‐amount fraud, rather than incorrectly classifying every large deposit as legitimate.

We built our GBT classifier in PySpark, monitoring performance via AUC metrics, Gains charts, and the rate of fraud capture. After tuning hyperparameters (like tree depth and learning rate) and implementing the bucketing approach for big checks, the model significantly improved its ability to detect both small‐value and high‐value fraudulent checks—far exceeding the performance of the previous rules‐based system. Overall, it was a great learning experience in imbalanced data handling, feature engineering, and the art of guiding tree‐based models to capture rare, high‐impact events.”
