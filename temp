from datetime import datetime, timedelta
from pyspark.sql import functions as F

def create_temp_view_of_lookup(
    spark,
    first_date: str,
    last_date: str,
):
    """
    Builds the pop_accts-like lookup temp view that unions RBO + OAO sources.

    Parameters
    ----------
    first_date : 'YYYY-MM-DD'
    last_date  : 'YYYY-MM-DD'
    """

    # --- your existing RBO code above this point (unchanged) ---
    # ... rcb_base_pop, rcb_acct_nums, rcb_accts, etc.
    # (left out here just for brevity)

    # =========================
    # OAO accounts (your block)
    # oao partitions are updated from the previous partition, each includes ~previous 3 years
    # =========================

    # >>> CHANGED: helper to pick up to 4 OAO partitions that cover [first_date, last_date]
    def _pick_oao_partitions(table: str, first_date: str, last_date: str):
        """Return up to four partition dates (as strings) for `table`:
           start at the first partition >= last_date; then walk backwards
           until its 3-year coverage crosses first_date (or we have 4 dates)."""
        # all available partition dates (strings) for this table
        all_parts = (
            spark.table(table)
                 .select(F.col("ods_business_dt").cast("date").alias("dt"))
                 .distinct()
                 .collect()
        )
        parts = sorted({r["dt"].strftime("%Y-%m-%d") for r in all_parts})

        # find the first partition >= last_date
        anchor = None
        for p in parts:
            if p >= last_date:
                anchor = p
                break
        # if none >= last_date, take the last available one
        if anchor is None and parts:
            anchor = parts[-1]

        if not anchor:
            return []

        # walk backwards until coverage hits first_date (or 4 partitions)
        chosen = [anchor]
        anchor_dt = datetime.strptime(anchor, "%Y-%m-%d").date()
        first_dt = datetime.strptime(first_date, "%Y-%m-%d").date()

        # coverage for a snapshot partition is (partition_date - 3 years) .. partition_date
        def covers_start(p_str: str) -> bool:
            p = datetime.strptime(p_str, "%Y-%m-%d").date()
            return (p - timedelta(days=365*3)) <= first_dt

        if covers_start(anchor):
            return chosen

        # walk to earlier partitions
        idx = parts.index(anchor)
        while idx > 0 and len(chosen) < 4:
            idx -= 1
            prev_p = parts[idx]
            chosen.append(prev_p)
            if covers_start(prev_p):
                break

        return chosen

    # >>> CHANGED: compute oao_dt1..oao_dt4 dynamically for each table
    oao_dt_list_app  = _pick_oao_partitions("sl1_oao.tbl_application_h",  first_date, last_date)
    oao_dt_list_cust = _pick_oao_partitions("sl1_oao.tbl_customerproducts_h", first_date, last_date)
    oao_dt_list_prod = _pick_oao_partitions("sl1_oao.tbl_products_h",     first_date, last_date)
    oao_dt_list_ptyp = _pick_oao_partitions("sl1_oao.tbl_producttype_h",  first_date, last_date)

    # keep your original variable names
    oao_dt1 = oao_dt_list_app[0]  if len(oao_dt_list_app)  > 0 else None
    oao_dt2 = oao_dt_list_cust[0] if len(oao_dt_list_cust) > 0 else None
    oao_dt3 = oao_dt_list_prod[0] if len(oao_dt_list_prod) > 0 else None
    oao_dt4 = oao_dt_list_ptyp[0] if len(oao_dt_list_ptyp) > 0 else None

    # --- your original OAO frames, unchanged except the dt variables come from above ---

    oao_base_pop = (  # has same application ids as tbl_application_h
        spark.table("sl1_oao.tbl_customer_h")
            .filter(F.col("ods_business_dt") == oao_dt1)
            .select(
                F.col("id").alias("consumer_id"),
                F.col("applicationid").alias("session_id"),
            )
            .distinct()
    )

    oao_acct_nums = (
        spark.table("sl1_oao.tbl_customerproducts_h")
            .filter(F.col("ods_business_dt") == oao_dt2)  # TODO in your code said "check partitions" â€“ now resolved by picker
            .filter(F.col("productid").isin(1,2,6,7,11,60,64,65,76,86,87,88,91,97,98,99,107,111,114,126))
            .select(
                F.col("applicationid").alias("session_id"),
                F.col("newaccountnumber").cast("bigint").alias("newaccountnumber"),
                F.col("productid"),
            )
            .distinct()
    )

    oao_products = (
        spark.table("sl1_oao.tbl_products_h")
            .filter(F.col("ods_business_dt") == oao_dt3)
            .select(
                F.col("id").alias("productid"),
                F.col("productcd").alias("productcd"),
            )
            .distinct()
    )

    oao_prod_types = (
        spark.table("sl1_oao.tbl_producttype_h")
            .filter(F.col("ods_business_dt") == oao_dt4)
            .select(
                F.col("id").alias("producttypeid"),
                F.col("name").alias("product_type"),
            )
            .distinct()
    )

    oao_accts = (
        oao_acct_nums
            .join(oao_products, on="productid", how="left")
            .join(oao_prod_types, on=F.lower(F.col("productcd")) == F.lower(F.col("product_type")), how="left")
            .join(oao_base_pop, on="session_id", how="left")
            .filter(~F.col("productcd").isin(F.lit(None)))  # (kept your filtering style; adjust if you had a different one)
            .select(
                F.col("newaccountnumber").alias("accountnumber"),
                F.col("consumer_id"),
                F.col("session_id"),
                F.col("productcd"),
            )
            .distinct()
    )

    # --- your existing union + final temp view creation (unchanged) ---
    # final_lookup = rcb_accts.unionByName(oao_accts)  # or your existing union logic
    # final_lookup.createOrReplaceTempView("do_account_lookup")  # or your target temp view name

