Below is a **revised “Model Description”** chapter that clarifies Version 5 is effectively the **same GBT approach** as Version 3 (currently in production), only **retrained** with updated data and parameters.  

---

## 3. Model Description

This section outlines the **theoretical framework**, **methodology**, and **intuitive rationale** behind the Inclearing Fraud Model (Version 5). Notably, Version 5 is functionally the **same Gradient Boosted Trees (GBT) approach** as Version 3, the current production model—only **retrained** on updated historical data for enhanced accuracy.

### 3.1. Theoretical Framework

The Inclearing Fraud Model relies on a **non‐parametric, ensemble learning** method known as **gradient boosting**:

- **Ensemble Methods**: Multiple “weak learners” (decision trees) are combined to form a single, stronger predictive model.  
- **Gradient Descent**: The algorithm incrementally reduces an objective loss (e.g., logistic loss for classification) by fitting new trees to the *residual errors* from prior trees.  
- **Published Foundations**: The approach builds on Friedman’s (2001) seminal work in gradient boosting for classification/regression tasks.

Since Version 5 inherits the same GBT methodology as Version 3, no additional changes to the fundamental model architecture were required beyond updating the training data and parameter tuning.

### 3.2. Selected Methodology

The **Gradient Boosted Trees** (GBT) process is retained from the previous version:

1. **Initialization**: The model starts with a simple prediction (e.g., average fraud rate).  
2. **Iterative Boosting**: Each new tree \( h_m(x) \) is fit to the current residuals, then the ensemble updates via  
   \[
   F_m(x) = F_{m-1}(x) + \nu \cdot h_m(x),
   \]
   where \( \nu \) is the learning rate.  
3. **Final Ensemble**: After \( M \) iterations, the final output is a sum of all trees plus the initial prediction, yielding a **fraud score** for each transaction.

**Version 5** re‐runs these steps on **refreshed training data** (spanning an updated time window), applying similar hyperparameters and transformations that were proven successful in Version 3.

Below is a **revised “Model Development Process Flow”** section that **replaces** the original statement about having equal numbers of events and non‐events. The updated text explains the **partial upsampling** procedure and notes that the final ratio depends on a hyperparameter rather than forcing a strict 1:1 balance.

---

### 3.3 Model Development Process Flow

The model development process began with the dataset described in the previous section. This developmental dataset is **pre‐processed** via Spark ML’s pipelines to create dummy variables for the categorical fields and to assemble the features vector for model training. The data is then **split** into a 70/30 train/test partition.  

Next, the **training data** undergoes **partial upsampling** of fraudulent (event) records using a custom function (`handle_imbalanced_data`). This function duplicates each fraud row a certain number of times, determined by a hyperparameter “factor,” thereby **increasing** the proportion of fraud items but **not necessarily** creating a 1:1 ratio. The resulting sample remains less skewed, which helps the model better distinguish between rare fraud events and the majority of legitimate transactions.

The two candidate models were developed with the **`GBTClassifier()`** algorithm from the Spark ML library. Hyperparameter sets were compared among each other using the following steps to determine the champion model:

1. **Calculate falloff under the curve (AUC)** for the precision/recall curve (PR) and the receiver operating characteristic (ROC) curve between the train and test sets.  
2. **Select model hyperparameter sets** to perform a Gains table comparison on the chosen model sets.  
3. **Select the final model** with hyperparameters.  
4. **Perform out‐of‐time testing** to ensure the model will generalize to new data.

Inclearing Fraud Model V5 re‐runs these same steps on an **updated training data window** from 2024‐04‐22 to 2024‐10‐08, applying similar hyperparameters and transformations proven successful in Version 3.

### 3.4. Intuition Behind the Relationships

In fraud detection, certain behavioral and transactional features are predictive indicators of risk. The GBT method allows flexible “branching” on variables such as **check amount**, **account tenure**, **transaction frequency**, etc., capturing complex interaction effects automatically.  

**Version 5** continues to exploit these patterns, with no new theoretical assumptions. The difference is that **updated training data** may improve sensitivity to newer fraud trends or patterns that emerged since the last model retraining.

### 3.5. Alignment with Business and Regulatory Requirements

- **Business Goals**: Reducing fraud losses remains the primary objective. By retraining on the latest data, Version 5 ensures that the model adapts to recent fraud schemes.  
- **Regulatory & Risk Oversight**: Detailed documentation of data sources, transformations, and model parameters is consistent with Model Risk Management guidelines. Retaining the GBT architecture also simplifies model governance since core methodology remains unchanged.

### 3.6. Assumed Relationships and Empirical Evidence

As a **non‐parametric** model, GBT does not impose strict linear or distributional assumptions. Instead, relationships are inferred from historical patterns of confirmed fraud vs. non‐fraud items. Past performance of Version 3 established evidence that GBT effectively ranks potential fraud. **Version 5** leverages the same approach with updated evidence, reinforcing the method’s validity.

### 3.7. Illustrative Graphs of Hypothesized Interactions

*(Optional: If partial dependence plots or feature importances from Version 5 are available, they can be shown to highlight how the model’s major drivers have or have not changed from Version 3.)*

---

**In summary**, **Version 5** is a **retrained** iteration of the **Gradient Boosted Trees** model already in production as Version 3. It applies the same ensemble learning principles and flow, using newly refreshed data to ensure that the model remains effective at distinguishing fraudulent transactions under current conditions.
---

**In summary**, the Inclearing Fraud Model V3 uses a **Gradient Boosted Trees** framework to rank transactions by fraud likelihood. This approach is theoretically rooted in ensemble methods and gradient descent optimization, and it captures nonlinear patterns essential for accurately identifying fraudulent behavior. The model meets key business and regulatory objectives by producing robust, explainable risk scores that integrate seamlessly into existing fraud detection workflows.

# 8. Model Implementation

This chapter explains how the updated Inclearing Fraud Model (Version 3) is deployed and integrated within the organization’s production environment, including data sources, transformations, and the reporting mechanism for fraud risk scores.

## 8.1. Summary of Model Implementation

The Inclearing Fraud Model V3 is implemented as part of the **Financial Crimes Non‐Card Transaction** fraud detection pipeline. It uses **PySpark** on **[CDSW / Spark cluster / internal big data platform]** to generate daily fraud scores for each inclearing transaction. These scores feed into the **Fraud Operations** rules engine, enabling real‐time or near‐real‐time alerts for potential fraudulent checks.

- **Application / System**:  
  - The model’s output is ingested into **Detica** (the downstream case management system), where Fraud Operations reviews high‐risk items.  
- **Code Platform and Prediction Flow**:  
  - The scoring code is stored in **[Bitbucket / GitHub / internal repository]**.  
  - During each production cycle, the pipeline reads inclearing transactions from the **Data Lake** (same as previous model version), applies the GBT model to compute a fraud likelihood score, and writes back the scored data to a **production table** for consumption by downstream applications.

Because the model architecture (a Gradient Boosted Classifier) and data ingestion pipeline are the same as in the previous version, minimal adjustments were needed beyond retraining on updated historical data.

## 8.2. Production Data Sources, Preparation, and Transformations

### 8.2.1. Data Pipeline

1. **Implementation/Prediction Pipeline**  
   - The system extracts daily inclearing transactions from **`dm_fraud_detection.inc_frd_<...>`** (or equivalent) within the Data Lake.  
   - A PySpark job transforms the raw data, applies feature engineering steps (similar to those used in model development), and feeds the resulting features into the GBT model object.  
   - The model scores each transaction, outputting the predicted probability of fraud (i.e., fraud score).

2. **Reference to Applicable Code**  
   - The Spark job is orchestrated via **[Airflow / internal scheduler]**.  
   - Code is tracked in **Bitbucket** under the repository **`<repo_name>`**, ensuring version control for any changes to data transformations.

### 8.2.2. Data Sources for Model Implementation

- **Inclearing Transaction Table** (`SB_FRAUD_NCA.incI_mth` or similar):  
  - Primary source of deposit items for scoring.  
  - Includes check amount, account details, transaction history, and other features.  
- **Supporting Tables** (internal to Regions):  
  - **SL1_DM, SL1_RF, SL1_DNCCR,** etc., used to enrich the transaction records with relationship, login, or case management attributes.  
- **Vendor Data (if applicable)**:  
  - As with the old model, no external vendor data is directly consumed at scoring time. All enhancements remain internal.

### 8.2.3. Weaknesses and Limitations in Source Data

- **Missing Fields or Records**:  
  - Rarely, certain checks may lack critical fields (e.g., no item serial number). As in the old model, these items receive partial scoring or default values.  
- **Infrequent Data Delays**:  
  - Overnight ingestion delays can occasionally cause a small subset of transactions to miss the day’s scoring window. They are captured and scored retroactively once the data is complete.

### 8.2.4. Data Appropriateness and Accuracy

The production data follows the same schema and cleaning rules as the development dataset, ensuring consistency. Periodic data audits confirm alignment between the development sample and live production feeds. If any outlier patterns emerge (e.g., new transaction codes), updates are made to the transformation logic to maintain model accuracy.

### 8.2.5. Handling Missing or Unknown Values

Any missing numeric fields continue to be imputed with **[–999 or 0, as appropriate]**, consistent with the approach taken during model training. Categoricals that are unrecognized or empty default to “unknown” categories. This approach has been retained from the old model to ensure consistent scoring behavior.

## 8.3. Production Environment

The production environment is hosted on **[CDSW / Hadoop Yarn / Spark cluster name]**, where the PySpark scoring pipeline executes on a daily schedule. The environment automatically pulls together the relevant data tables, runs feature transformations, and applies the GBT model. Key aspects:

1. **Data Integration & Model Execution**  
   - The daily job merges inclearing checks with relevant reference tables.  
   - The GBT scoring step runs after successful data ingestion, generating a **fraud score** per item.

2. **Rules and Overrides**  
   - The final fraud detection process relies on a combination of model output plus any business rules. For instance, certain high‐risk item types might be flagged regardless of model score.  
   - These overrides are the same ones used with the old model; they have been tested with the new GBT scores to confirm compatibility.

3. **Control / Production Checks**  
   - The pipeline logs each step’s status (extraction, transformation, scoring) to a monitoring dashboard.  
   - Reconciliation checks ensure that the number of rows scored matches the expected count of daily transactions.  
   - If errors occur, the pipeline triggers alerts to the Data & Analytics team to investigate and re‐run if necessary.

## 8.4. Model Output and Reporting

### 8.4.1. How Output Is Used and Weighed

The model outputs a numeric probability (fraud likelihood) for every check. Fraud Operations uses these scores to prioritize which items undergo a deeper investigation:

- **Score Thresholds**: If the predicted fraud likelihood exceeds certain cutoffs (e.g., top 5%), an alert is created in **Detica**.  
- **Further Processing**: No additional models consume the GBT output. The risk score is integrated directly into the existing rule engine for advanced decision logic.

### 8.4.2. Transmission and Automation Controls

Once daily scoring is complete, the resulting dataset (with final scores) is written to **[HDFS / a production table / object storage]**. Fraud Operations systems fetch these scores in near‐real time, applying them to:

- **Alerts**: An item with a high fraud score triggers an immediate alert for manual review.  
- **Reporting**: Summaries of daily alerts and captured fraud amounts are compiled in standard management reports.

### 8.4.3. Datasets Storing Model Results

- **Production Scored Table**: **`dm_fraud_detection.inc_frd_scored_v3`** (example naming) stores each check’s final features, the GBT score, and relevant metadata (date/time of scoring, system run ID, etc.).  
- **Historical Audit Dataset**: Archives older daily outputs, ensuring traceability for compliance and monitoring.

### 8.4.4. Disclaimers, Information, and Assumptions

- **Model Uncertainty**: The GBT score is a statistical estimate, not a definitive fraud/no‐fraud determination.  
- **Use of Imputed Values**: Missing data is imputed following the same scheme as training. This is highlighted in the model documentation to warn users that extremely missing data could reduce confidence in the score.  
- **Interpretation**: The final decision (to return or pay a check) remains the responsibility of Fraud Operations, guided by the model’s ranking but supplemented by domain expertise.

### 8.4.5. Controls and Reviews

- **Operational Reviews**: The business regularly reviews performance metrics (e.g., daily fraud capture, false positives) to ensure the model continues meeting goals.  
- **Committee Acceptance**: Any major changes to thresholds or the scoring pipeline are presented to the Model Risk Management committee for approval, maintaining governance standards.

---

**In summary**, the **Model Implementation** for Version 3 follows the same robust pipeline and operational framework as its predecessor. It leverages existing data sources, transformations, and rule sets—requiring only minimal adjustments to accommodate the newly trained GBT model. This consistent design ensures minimal disruption while introducing improved fraud detection capability.
