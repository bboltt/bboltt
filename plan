

## 3. Model Description

This section outlines the **theoretical framework**, **methodology**, and **intuitive rationale** underlying the Inclearing Fraud Model (Version 3). Although the core algorithm (Gradient Boosted Trees, or GBT) is an advanced machine learning technique, we describe how it fits within the business and risk management environment, referencing relevant empirical evidence and depicting the process flow.

### 3.1. Theoretical Framework

The Inclearing Fraud Model leverages a **non‐parametric, ensemble learning** method based on the concept of **gradient boosting**:

- **Ensemble Methods**: Ensemble techniques combine multiple “weak learners” (in this case, decision trees) to produce a stronger predictive model.  
- **Gradient Descent**: The method incrementally reduces an objective loss (e.g., a logistic loss for classification) by fitting new trees that address the *residual errors* from prior trees.  
- **Published Foundations**: This approach builds on foundational work by Friedman (2001) in gradient boosting for classification and regression.  

By using gradient boosting, the model captures **nonlinear relationships** and **complex interactions** among the features without requiring linear‐model assumptions.

### 3.2. Selected Methodology

The chosen **Gradient Boosted Trees** algorithm iteratively trains a sequence of shallow decision trees (weak learners). Each new tree focuses on correcting the errors made by the ensemble thus far. Formally, if we let \( F_{m-1}(x) \) represent the ensemble’s prediction after \( m-1 \) trees, the algorithm learns a new tree \( h_m(x) \) that fits the negative gradient (residuals) of the loss function at iteration \( m \). The model then updates:
\[
F_m(x) = F_{m-1}(x) + \nu \cdot h_m(x),
\]
where \( \nu \) (the step size or learning rate) scales how aggressively each new tree contributes.

1. **Initialization**: Start with a constant model, often the average label (fraud or non‐fraud) or a log odds value.  
2. **Iterative Tree Building**: For each boosting iteration:
   - Compute residuals based on the current ensemble’s predictions.  
   - Fit a decision tree to these residuals.  
   - Update the ensemble by adding this tree (scaled by the learning rate).  
3. **Final Ensemble**: After \( M \) iterations, the final model is the sum of all learned trees plus the initial prediction.  

### 3.3. Flow Chart of the Process

Below is a simplified schematic of the end‐to‐end procedure. Each numbered step corresponds to a subsection below.

```
   ┌─────────────────┐
(1)│    Data Input   │
   └─────────────────┘
          ↓
   ┌────────────────────────┐
(2)│Feature Engineering     │
   │ (fill missing data,    │
   │ create derived vars)   │
   └────────────────────────┘
          ↓
   ┌────────────────────────┐
(3)│Gradient Boosted Trees  │
   │  - Initialize model    │
   │  - Iteratively build   │
   │    shallow trees       │
   └────────────────────────┘
          ↓
   ┌────────────────────────┐
(4)│ Final Fraud Score      │
   │   (Prediction)         │
   └────────────────────────┘
```

1. **Data Input**: Reads the relevant inclearing transaction data plus historical account attributes.  
2. **Feature Engineering**: Cleans, transforms, or aggregates fields (e.g., maximum check amount, daily deposit frequency). Missing numeric values are imputed with a placeholder like –999.  
3. **Gradient Boosted Trees**: Builds and refines the model across multiple boosting iterations, improving classification accuracy for fraudulent vs. legitimate checks.  
4. **Final Output**: Produces a probability (or “fraud score”) used by Fraud Operations and rules engines.

### 3.4. Intuition Behind the Relationships

This GBT approach exploits the fact that **fraudulent checks** often exhibit patterns distinct from normal account behavior. Examples include:

- **Transaction Amount**: Fraudulent checks may display unusually high or inconsistent deposit amounts.  
- **Account History**: Repeated high‐value deposits in a short time can signal elevated risk.  
- **User Behaviors**: Features derived from login frequency or unusual IP geolocations might capture suspicious activity.

By letting decision trees naturally segment the data based on these variables, the model effectively uncovers complex, nonlinear interactions (e.g., “very large deposit amounts *plus* recently opened account *plus* unusual IP usage”) without manual rule‐writing.

### 3.5. Alignment with Business and Regulatory Requirements

- **Business Needs**: The model is designed to reduce check fraud losses and operational overhead by improving the accuracy of fraud alerts. This aligns with broader organizational goals of mitigating financial risk.  
- **Risk Management**: By adopting an ensemble method that is robust to correlated features and missing data, the model addresses real‐world complexities.  
- **Compliance & Oversight**: The approach is fully documented (data inputs, transformations, model parameters), facilitating model risk governance processes.

### 3.6. Assumed Relationships and Empirical Evidence

Because the model is non‐parametric, it does not assume linear or additive relationships; rather, it learns them from historical data. Nonetheless, internal **correlation analysis** and **feature importance** checks support the significance of certain attributes (e.g., deposit frequency, account tenure). Past pilot studies demonstrate that capturing these interactions improves detection rates compared to simpler logistic models.

### 3.7. Illustrative Graphs of Hypothesized Interactions

*(Optional: if you have partial dependence plots or feature interaction graphs, include them here.)*  
For example, a partial dependence plot for “Check Amount” might reveal an inflection point above which the probability of fraud jumps significantly, especially for newer accounts. Such visualizations confirm the intuitive notion that large checks on young accounts carry higher risk.

---

**In summary**, the Inclearing Fraud Model V3 uses a **Gradient Boosted Trees** framework to rank transactions by fraud likelihood. This approach is theoretically rooted in ensemble methods and gradient descent optimization, and it captures nonlinear patterns essential for accurately identifying fraudulent behavior. The model meets key business and regulatory objectives by producing robust, explainable risk scores that integrate seamlessly into existing fraud detection workflows.

# 8. Model Implementation

This chapter explains how the updated Inclearing Fraud Model (Version 3) is deployed and integrated within the organization’s production environment, including data sources, transformations, and the reporting mechanism for fraud risk scores.

## 8.1. Summary of Model Implementation

The Inclearing Fraud Model V3 is implemented as part of the **Financial Crimes Non‐Card Transaction** fraud detection pipeline. It uses **PySpark** on **[CDSW / Spark cluster / internal big data platform]** to generate daily fraud scores for each inclearing transaction. These scores feed into the **Fraud Operations** rules engine, enabling real‐time or near‐real‐time alerts for potential fraudulent checks.

- **Application / System**:  
  - The model’s output is ingested into **Detica** (the downstream case management system), where Fraud Operations reviews high‐risk items.  
- **Code Platform and Prediction Flow**:  
  - The scoring code is stored in **[Bitbucket / GitHub / internal repository]**.  
  - During each production cycle, the pipeline reads inclearing transactions from the **Data Lake** (same as previous model version), applies the GBT model to compute a fraud likelihood score, and writes back the scored data to a **production table** for consumption by downstream applications.

Because the model architecture (a Gradient Boosted Classifier) and data ingestion pipeline are the same as in the previous version, minimal adjustments were needed beyond retraining on updated historical data.

## 8.2. Production Data Sources, Preparation, and Transformations

### 8.2.1. Data Pipeline

1. **Implementation/Prediction Pipeline**  
   - The system extracts daily inclearing transactions from **`dm_fraud_detection.inc_frd_<...>`** (or equivalent) within the Data Lake.  
   - A PySpark job transforms the raw data, applies feature engineering steps (similar to those used in model development), and feeds the resulting features into the GBT model object.  
   - The model scores each transaction, outputting the predicted probability of fraud (i.e., fraud score).

2. **Reference to Applicable Code**  
   - The Spark job is orchestrated via **[Airflow / internal scheduler]**.  
   - Code is tracked in **Bitbucket** under the repository **`<repo_name>`**, ensuring version control for any changes to data transformations.

### 8.2.2. Data Sources for Model Implementation

- **Inclearing Transaction Table** (`SB_FRAUD_NCA.incI_mth` or similar):  
  - Primary source of deposit items for scoring.  
  - Includes check amount, account details, transaction history, and other features.  
- **Supporting Tables** (internal to Regions):  
  - **SL1_DM, SL1_RF, SL1_DNCCR,** etc., used to enrich the transaction records with relationship, login, or case management attributes.  
- **Vendor Data (if applicable)**:  
  - As with the old model, no external vendor data is directly consumed at scoring time. All enhancements remain internal.

### 8.2.3. Weaknesses and Limitations in Source Data

- **Missing Fields or Records**:  
  - Rarely, certain checks may lack critical fields (e.g., no item serial number). As in the old model, these items receive partial scoring or default values.  
- **Infrequent Data Delays**:  
  - Overnight ingestion delays can occasionally cause a small subset of transactions to miss the day’s scoring window. They are captured and scored retroactively once the data is complete.

### 8.2.4. Data Appropriateness and Accuracy

The production data follows the same schema and cleaning rules as the development dataset, ensuring consistency. Periodic data audits confirm alignment between the development sample and live production feeds. If any outlier patterns emerge (e.g., new transaction codes), updates are made to the transformation logic to maintain model accuracy.

### 8.2.5. Handling Missing or Unknown Values

Any missing numeric fields continue to be imputed with **[–999 or 0, as appropriate]**, consistent with the approach taken during model training. Categoricals that are unrecognized or empty default to “unknown” categories. This approach has been retained from the old model to ensure consistent scoring behavior.

## 8.3. Production Environment

The production environment is hosted on **[CDSW / Hadoop Yarn / Spark cluster name]**, where the PySpark scoring pipeline executes on a daily schedule. The environment automatically pulls together the relevant data tables, runs feature transformations, and applies the GBT model. Key aspects:

1. **Data Integration & Model Execution**  
   - The daily job merges inclearing checks with relevant reference tables.  
   - The GBT scoring step runs after successful data ingestion, generating a **fraud score** per item.

2. **Rules and Overrides**  
   - The final fraud detection process relies on a combination of model output plus any business rules. For instance, certain high‐risk item types might be flagged regardless of model score.  
   - These overrides are the same ones used with the old model; they have been tested with the new GBT scores to confirm compatibility.

3. **Control / Production Checks**  
   - The pipeline logs each step’s status (extraction, transformation, scoring) to a monitoring dashboard.  
   - Reconciliation checks ensure that the number of rows scored matches the expected count of daily transactions.  
   - If errors occur, the pipeline triggers alerts to the Data & Analytics team to investigate and re‐run if necessary.

## 8.4. Model Output and Reporting

### 8.4.1. How Output Is Used and Weighed

The model outputs a numeric probability (fraud likelihood) for every check. Fraud Operations uses these scores to prioritize which items undergo a deeper investigation:

- **Score Thresholds**: If the predicted fraud likelihood exceeds certain cutoffs (e.g., top 5%), an alert is created in **Detica**.  
- **Further Processing**: No additional models consume the GBT output. The risk score is integrated directly into the existing rule engine for advanced decision logic.

### 8.4.2. Transmission and Automation Controls

Once daily scoring is complete, the resulting dataset (with final scores) is written to **[HDFS / a production table / object storage]**. Fraud Operations systems fetch these scores in near‐real time, applying them to:

- **Alerts**: An item with a high fraud score triggers an immediate alert for manual review.  
- **Reporting**: Summaries of daily alerts and captured fraud amounts are compiled in standard management reports.

### 8.4.3. Datasets Storing Model Results

- **Production Scored Table**: **`dm_fraud_detection.inc_frd_scored_v3`** (example naming) stores each check’s final features, the GBT score, and relevant metadata (date/time of scoring, system run ID, etc.).  
- **Historical Audit Dataset**: Archives older daily outputs, ensuring traceability for compliance and monitoring.

### 8.4.4. Disclaimers, Information, and Assumptions

- **Model Uncertainty**: The GBT score is a statistical estimate, not a definitive fraud/no‐fraud determination.  
- **Use of Imputed Values**: Missing data is imputed following the same scheme as training. This is highlighted in the model documentation to warn users that extremely missing data could reduce confidence in the score.  
- **Interpretation**: The final decision (to return or pay a check) remains the responsibility of Fraud Operations, guided by the model’s ranking but supplemented by domain expertise.

### 8.4.5. Controls and Reviews

- **Operational Reviews**: The business regularly reviews performance metrics (e.g., daily fraud capture, false positives) to ensure the model continues meeting goals.  
- **Committee Acceptance**: Any major changes to thresholds or the scoring pipeline are presented to the Model Risk Management committee for approval, maintaining governance standards.

---

**In summary**, the **Model Implementation** for Version 3 follows the same robust pipeline and operational framework as its predecessor. It leverages existing data sources, transformations, and rule sets—requiring only minimal adjustments to accommodate the newly trained GBT model. This consistent design ensures minimal disruption while introducing improved fraud detection capability.
