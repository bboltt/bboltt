Below is an example **“Portfolios”** chapter that mirrors your provided format but reflects the reality that you have **only one model** (i.e., no separate sub‐models by segment or channel). The text references a single consolidated table that tracks total transaction counts, amounts, and fraud metrics over time.

---

## 2. Portfolios

In this project, the inclearing fraud model covers all consumer deposit checks in a unified manner rather than splitting them by segment or channel. Consequently, we do not maintain sub‐models (like ATM or branch sub‐models). Instead, a single portfolio captures every in‐scope deposit transaction for the relevant timeframe.

To monitor activity within this single portfolio, the team compiles a table summarizing each week’s or month’s transactions. This table may include:

week_start (or month_start): The date marking the beginning of the reporting interval
total_count: Number of inclearing deposit transactions during that interval
total_amount: Sum of dollar amounts for those deposits
Tier 1 count and Tier 1 amount (if applicable): Number and total value of deposits returned for Tier 1 fraud reasons (e.g., forgery, altered item)
total_fraud count and total_fraud_amount: Overall confirmed fraud cases identified in that period
Other columns capturing additional data or derived metrics, such as the percentage of items flagged, alt text usage, or “unt_percentage” if relevant
In this hypothetical layout, **every** deposit transaction is part of one combined set—no separate ATM, branch, or mobile sub‐model. By reviewing columns such as **`total_count`**, **`total_amount`**, and **`total_fraud_amount`**, stakeholders can evaluate the model’s performance and identify any spikes in fraudulent activity over time.

In this hypothetical layout, every deposit transaction is part of one combined set—no separate ATM, branch, or mobile sub‐model. By reviewing columns such as total_count, total_amount, and total_fraud_amount, stakeholders can evaluate the model’s performance and identify any spikes in fraudulent activity over time.

Because the deposit checks are not segmented by channel, the table provides a straightforward, all‐encompassing view of the deposit portfolio’s transaction volume, associated fraud returns, and key metrics to monitor trends week to week or month to month.






8.2. Production Data Sources, Preparation, and Transformations
Implementation / Prediction Data Pipeline

In production, the same Spark pipeline used for development runs daily within the CDSW environment. It pulls inclearing transactions from the Data Lake, applies the identical feature‐engineering steps (Mitek image analysis, device/log data, account balances, etc.), and then generates a fraud score with the GBT model.
Data Sources

The model references the same internal Regions systems as in development:
dm_fraud_detection.incI_mtk_h for the base inclearing transactions
SL1_DM, SL1_FDP_MTK, SL1_DNCCW, SL1_MBANK for account, Mitek, call center, and mobile banking data
No external vendor data is introduced at this stage; these sources remain fully internal to Regions.
Weaknesses and Limitations

Because the production data pipeline is identical to the developmental one, any potential issues (e.g., missing Mitek scores for certain checks, incomplete device logs) remain possible.
If upstream tables are not updated or contain null fields, the pipeline uses fill values or leaves some features at defaults (e.g., zero).
Data Appropriateness and Accuracy

As with development data, the final production dataset undergoes the same joins and aggregations. The result is consistent with the training structure.
There is no difference in the data logic or feature transformations; the only change is that transactions now reflect each day’s real‐time inclearing items rather than a historical sample.
Assumed Values for Missing Data

Just as in development, missing numeric fields (e.g., account balances, checkscore) default to zero, or a placeholder flag indicates incomplete records. This approach ensures that no rows are dropped due to nulls.
Overall, the production pipeline replicates the developmental data sources and transformations, ensuring the daily inclearing items receive the same feature engineering and labeling logic that was validated during model development.
---

# Data Preparation and Transformation

## 1. Base Transaction Data

The main dataset originates from a table named **`dm_fraud_detection.incI_mtk_h`**, which contains individual inclearing deposit transactions. For each transaction, the script selects columns such as:

- **`account_num`**: Unique identifier for the checking or savings account  
- **`amount`**: Dollar value of the check deposit  
- **`trans_date`** and **`trans_time`**: Date and time of deposit  
- **`serial`**: Check serial number  
- **Daily columns** (e.g., `daily_max`, `day_amount`, `day_balance`) that track per‐day deposit usage

This base table underpins the modeling dataset, with one row per deposit transaction.

---

## 2. Feature Enrichment

Once the base transactions are loaded, the pipeline joins multiple **feature modules** to generate additional fields that describe each deposit’s context.

### 2.1. Mitek Check Analysis

A Mitek module gathers check‐image features from tables like `fdp_mitek_request` or `fdp_mitek_response_analysis_detail`. Common outputs include:

- **Checkscore** or **Addressscore** – Numeric ratings that reflect the likelihood of an altered or suspicious check image  
- **Suspectendorsement** – A flag indicating whether the endorsement region appears mismatched  
- **Miscscore** – Additional Mitek signals aggregated for the deposit

These fields are aggregated by `(account_num, trans_date, serial)` so that each deposit row gains Mitek’s maximum or minimum rating over the check’s entire analysis record.

### 2.2. Account Balance and Savings Data

Another module queries deposit and savings account tables (e.g., `SL1_DM.ds002.dm14d_dmsave_h`) to retrieve:

- **Average / standard deviation** of the account balance over a specified window (e.g., 30, 60 days)  
- **Recent deposit velocity** – how frequently funds are coming in  
- **Return records** – whether the account had a prior returned item

These balance and return statistics are grouped by `account_num` and then merged with each deposit. Columns might appear as `avg_bal_30`, `std_bal_30`, or `rtn_acct_flag` to flag historically returned accounts.

### 2.3. Device Usage and Login Patterns

A device module merges user sign‐on data from a mobile or internet banking table (e.g., `sl1_mbank.eventreporting_h`). For each account:

- **Device changes** – Checking if the user recently switched to a new device  
- **Odd hour** – Identifying logins at unusual times (e.g., after midnight)  
- **Geo or IP mismatch** – If the user’s location unexpectedly changed

These fields are keyed by `account_num` and a date window, so each deposit row can include relevant device usage signals.

### 2.4. Call Center Interactions

A call module looks at records from contact‐center platforms (e.g., `SL1_dnccw`) to assess:

- **Call reasons** or **wrap codes** – Documenting any unusual or high‐risk reason for contacting support  
- **Voice authentication** or **risk_color** – Indications from phone channel about potential fraud  
- **Escalation or verification** outcomes – Whether the call ended in additional screening

These metrics are typically aggregated at the account level over a short time horizon (such as 14 days around the deposit date) and joined to each deposit transaction.

### 2.5. Transaction Code Summaries

A transaction module classifies deposit or withdrawal codes (for instance, credit vs. debit) over different intervals (e.g., 30 days). It sums or counts them under columns like:

- **TX_GRP1_CR_AMT** or **TX_GRP1_DB_AMT** – Cumulative credit/debit amounts in certain code families  
- **CC_debit_cnt** – Number of card‐based withdrawals over that window  

These aggregates help flag anomalies, like unusually large or frequent deposits.

---

## 3. Fraud Label Assignment

After combining all feature sets, the pipeline appends a **fraud label**. This label is based on:

- **Fraud .NET** signals – If an item was confirmed fraudulent in the internal case‐management system  
- **Alerts** from the deposit platform – Marking a transaction as “check fraud” if it triggered a specialized alert code

If the deposit was ultimately deemed fraudulent, the label is set to `1`; otherwise `0`. This binary indicator is critical for model training and evaluation.

---

## 4. Data Quality Measures

To ensure consistency across the final dataset:

1. **Column Casting and Fill Values**  
   Numeric fields, such as amounts or Mitek scores, are cast to appropriate decimal or integer types. Missing values are replaced with 0 (or another default) to prevent dropping rows.

2. **Distinct and Filtered Joins**  
   When multiple feature sources return data for the same account or deposit date, the pipeline employs distinct row checks or carefully merges using left joins. This preserves the base deposit population while limiting duplication.

3. **Time‐Window Restriction**  
   Each feature module (call center, device logs, Mitek) retrieves only records that match the deposit’s timeframe (e.g., no future data). This keeps historical context aligned with deposit dates.

4. **Matching Keys**  
   Shared fields like `account_num`, `trans_date`, and `serial` enable consistent merging. The pipeline verifies these are present in both the base deposit DataFrame and each feature set.

---

## 5. Final Output

Once all features and the fraud label are joined, the pipeline **writes** the resulting dataset to a dedicated Hive or Parquet location. The final DataFrame thus represents a comprehensive view of each deposit’s:

- **Transaction details**  
- **Check image analysis**  
- **Account balances and returns**  
- **Device/login behavior**  
- **Call center interactions**  
- **Transaction code summaries**  
- **Binary fraud label**  

This integrated dataset serves as the foundation for further model development, training, and evaluation, ensuring that each deposit record contains the full suite of relevant signals to help identify potential fraud.
---

## 3. Model Description

This section outlines the **theoretical framework**, **methodology**, and **intuitive rationale** behind the Inclearing Fraud Model (Version 5). Notably, Version 5 is functionally the **same Gradient Boosted Trees (GBT) approach** as Version 3, the current production model—only **retrained** on updated historical data for enhanced accuracy.

### 3.1. Theoretical Framework

The Inclearing Fraud Model relies on a **non‐parametric, ensemble learning** method known as **gradient boosting**:

- **Ensemble Methods**: Multiple “weak learners” (decision trees) are combined to form a single, stronger predictive model.  
- **Gradient Descent**: The algorithm incrementally reduces an objective loss (e.g., logistic loss for classification) by fitting new trees to the *residual errors* from prior trees.  
- **Published Foundations**: The approach builds on Friedman’s (2001) seminal work in gradient boosting for classification/regression tasks.

Since Version 5 inherits the same GBT methodology as Version 3, no additional changes to the fundamental model architecture were required beyond updating the training data and parameter tuning.

### 3.2. Selected Methodology

The **Gradient Boosted Trees** (GBT) process is retained from the previous version:

1. **Initialization**: The model starts with a simple prediction (e.g., average fraud rate).  
2. **Iterative Boosting**: Each new tree \( h_m(x) \) is fit to the current residuals, then the ensemble updates via  
   \[
   F_m(x) = F_{m-1}(x) + \nu \cdot h_m(x),
   \]
   where \( \nu \) is the learning rate.  
3. **Final Ensemble**: After \( M \) iterations, the final output is a sum of all trees plus the initial prediction, yielding a **fraud score** for each transaction.

**Version 5** re‐runs these steps on **refreshed training data** (spanning an updated time window), applying similar hyperparameters and transformations that were proven successful in Version 3.

Below is a **revised “Model Development Process Flow”** section that **replaces** the original statement about having equal numbers of events and non‐events. The updated text explains the **partial upsampling** procedure and notes that the final ratio depends on a hyperparameter rather than forcing a strict 1:1 balance.

---

### 3.3 Model Development Process Flow

The model development process began with the dataset described in the previous section. This developmental dataset is **pre‐processed** via Spark ML’s pipelines to create dummy variables for the categorical fields and to assemble the features vector for model training. The data is then **split** into a 70/30 train/test partition.  

Next, the **training data** undergoes **partial upsampling** of fraudulent (event) records using a custom function (`handle_imbalanced_data`). This function duplicates each fraud row a certain number of times, determined by a hyperparameter “factor,” thereby **increasing** the proportion of fraud items but **not necessarily** creating a 1:1 ratio. The resulting sample remains less skewed, which helps the model better distinguish between rare fraud events and the majority of legitimate transactions.

The two candidate models were developed with the **`GBTClassifier()`** algorithm from the Spark ML library. Hyperparameter sets were compared among each other using the following steps to determine the champion model:

1. **Calculate falloff under the curve (AUC)** for the precision/recall curve (PR) and the receiver operating characteristic (ROC) curve between the train and test sets.  
2. **Select model hyperparameter sets** to perform a Gains table comparison on the chosen model sets.  
3. **Select the final model** with hyperparameters.  
4. **Perform out‐of‐time testing** to ensure the model will generalize to new data.

Inclearing Fraud Model V5 re‐runs these same steps on an **updated training data window** from 2024‐04‐22 to 2024‐10‐08, applying similar hyperparameters and transformations proven successful in Version 3.

### 3.4. Intuition Behind the Relationships

In fraud detection, certain behavioral and transactional features are predictive indicators of risk. The GBT method allows flexible “branching” on variables such as **check amount**, **account tenure**, **transaction frequency**, etc., capturing complex interaction effects automatically.  

**Version 5** continues to exploit these patterns, with no new theoretical assumptions. The difference is that **updated training data** may improve sensitivity to newer fraud trends or patterns that emerged since the last model retraining.

### 3.5. Alignment with Business and Regulatory Requirements

- **Business Goals**: Reducing fraud losses remains the primary objective. By retraining on the latest data, Version 5 ensures that the model adapts to recent fraud schemes.  
- **Regulatory & Risk Oversight**: Detailed documentation of data sources, transformations, and model parameters is consistent with Model Risk Management guidelines. Retaining the GBT architecture also simplifies model governance since core methodology remains unchanged.

### 3.6. Assumed Relationships and Empirical Evidence

As a **non‐parametric** model, GBT does not impose strict linear or distributional assumptions. Instead, relationships are inferred from historical patterns of confirmed fraud vs. non‐fraud items. Past performance of Version 3 established evidence that GBT effectively ranks potential fraud. **Version 5** leverages the same approach with updated evidence, reinforcing the method’s validity.

### 3.7. Illustrative Graphs of Hypothesized Interactions

*(Optional: If partial dependence plots or feature importances from Version 5 are available, they can be shown to highlight how the model’s major drivers have or have not changed from Version 3.)*

---

**In summary**, **Version 5** is a **retrained** iteration of the **Gradient Boosted Trees** model already in production as Version 3. It applies the same ensemble learning principles and flow, using newly refreshed data to ensure that the model remains effective at distinguishing fraudulent transactions under current conditions.
---

**In summary**, the Inclearing Fraud Model V3 uses a **Gradient Boosted Trees** framework to rank transactions by fraud likelihood. This approach is theoretically rooted in ensemble methods and gradient descent optimization, and it captures nonlinear patterns essential for accurately identifying fraudulent behavior. The model meets key business and regulatory objectives by producing robust, explainable risk scores that integrate seamlessly into existing fraud detection workflows.

# 8. Model Implementation

This chapter explains how the updated Inclearing Fraud Model (Version 3) is deployed and integrated within the organization’s production environment, including data sources, transformations, and the reporting mechanism for fraud risk scores.



# 5. Model’s Conceptual Framework

## 5.1. Definitions

### Phenomena or Events Under Consideration
The Inclearing Fraud Model focuses on **fraudulent check deposits** that pass through the inclearing process at Regions—specifically, checks drawn on Regions accounts and deposited at another institution, or vice versa, which may be **forged, altered, or otherwise unauthorized**. The overarching goal is to detect these items using historical account‐level and transaction‐level indicators.

### Target Variable
The model’s target variable is a binary **fraud indicator**:
- **`1`** if the check was ultimately confirmed or highly suspected as fraudulent, often via the Fraud .NET system or assigned Tier 1 return codes.
- **`0`** if the check was deemed legitimate and not returned for fraud reasons.

This classification stems from deposit platform data, supplemented by claims information in the Fraud .NET application. By uniting these sources, the model identifies which checks truly represent fraud events versus normal transactions.

---

## 5.2. Assumptions

1. **Fraud Label Accuracy**  
   The model presumes that the official dispositions—i.e., which checks are flagged as fraud—are fundamentally correct. This underpins the training data’s label column.

2. **Availability of Mitek Scores**  
   Some checks include a Mitek “suspect item” score. The assumption is that this score is reliably captured for most inclearing items. Where it’s missing, the model either imputes or omits that feature.

3. **Data Consistency Across Sources**  
   Multiple tables (e.g., SL1_DM, SL1_DNCCR, SL1_FDP_MTK, etc.) feed into the final training dataset. The process assumes that the merges and transformations among these data sources do not introduce major discrepancies or timing misalignments.

4. **Stable Patterns**  
   Although fraud tactics can evolve, the model implicitly assumes that key risk signals (e.g., large deposit amounts, repeated suspicious checks) remain relevant during the timeframe from development to production usage.

---

## 5.3. Limitations

1. **Exclusion of Commercial Accounts with Positive Pay**  
   The Inclearing Fraud Model does not process checks from commercial accounts under positive pay arrangements. Those items are handled by a separate system, so any fraud in that segment is out of scope.

2. **Occasional Missing Mitek Score**  
   If a check’s image is not processed or lacks sufficient quality, Mitek’s suspect‐item analysis may be unavailable. This can diminish the model’s effectiveness for those transactions.

3. **Potential Data Lags**  
   Because a returned check can be confirmed as fraud days or weeks after deposit, the most recent incidents may not be labeled in time for the training window. Some near‐term fraud items might therefore remain undetected in historical data used for model building.

4. **Rare Negative Amounts**  
   The dataset includes some unusual transactions (e.g., negative deposit amounts), which are not commonly encountered. The model does score these items, but performance on such edge cases may be less predictable.

Overall, while the Inclearing Fraud Model leverages a robust set of features and reliable labeling, these assumptions and limitations underscore the model’s dependence on timely data, consistent Mitek scores, and stable fraud definitions.



## 5.4. Model Specification, Segmentation, and Variable Selection

### Rationale for Chosen Theory, Methodology, and Specification

- **Coverage of Major Fraud Risk Factors**  
  From the start, the model design prioritized capturing signals tied to suspicious check amounts, repeated deposits within short time frames, and Mitek’s suspect‐item scoring. These variables represent **key risk drivers** for inclearing items. The team concluded that a **gradient boosting** approach (GBT) would best integrate these varied features—both numeric (like `amount` or `daily_max`) and categorical (like `DSM_MTYPE`)—while inherently managing non‐linear interactions among them.

- **Why Gradient Boosted Trees**  
  The documentation indicates that earlier explorations included traditional logistic regression and a neural network concept. Ultimately, tree‐based methods showed stronger performance with minimal feature encoding overhead. GBT, in particular, provided more stable and **highly ranked** fraud detection across the training/testing splits, outperforming alternative algorithms in AUC and Gains metrics.

- **No Separate Portfolio Segmentation**  
  Rather than segment checks by product or region, the development data included **all** inclearing items meeting the established filters (Section 2.2.1). The project team determined that a single, unified model would better accommodate cross‐account patterns of fraud, ensuring comprehensive coverage of risk factors.

### Alternative Methodologies
While logistic regression and a neural approach were considered, the final selection was **GBTClassifier** from Spark ML. The documentation highlights GBT’s ensemble advantage and robust handling of unbalanced classes, as well as strong empirical results in pilot Gains and AUC tests.

### Data Rebalancing
Because fraudulent checks represented only a small portion of total deposits, the dataset was **upsampled** to give the model more event samples. This partial duplication of fraud cases enabled the GBT to learn distinguishing signals more effectively.

### Segmentation
No specialized segmentation (e.g., by account type) was performed. Instead, the entire population—excluding only certain out‐of‐scope items like commercial positive‐pay checks—was scored collectively.

### Target Variable Experimentation
The model’s **binary target** (fraud or not) was derived from the **alert** and **claim** data in the deposit platform and the Fraud .NET application. No alternative definitions for the fraud label were tested, as the existing approach aligned with the bank’s operational claims process.

### Variable Selection
1. **Initial Feature Pool**  
   - The raw fields included numeric/categorical variables from multiple systems (SL1_DM, SL1_DNCCR, SL1_FDP_MTK).  
   - Variables reflecting check amounts, account usage, or Mitek analysis were the main drivers.  
2. **Feature Refinement**  
   - Dummy encoding converted relevant categorical fields (e.g., `DSM_MTYPE`) into numeric indicators.  
   - After exploratory analysis, the team retained only the fields most predictive of fraud (see Section 2.2.4).  

### Hyperparameter Selection
Key parameters—e.g., `maxDepth`, `maxBins`, `stepSize`, and `subsamplingRate`—were tuned via multiple runs on a 70/30 split. **AUC** and Gains chart performance guided the final choices, balancing detection gains and overfitting risks.

### Model Thresholds
The model outputs a **probability score** for each transaction. Downstream rules interpret these scores, setting thresholds that trigger specific alerts or actions. The documentation does not specify a single fixed cutoff inside the model itself.

---

**In summary**, the project team selected **GBTClassifier** for its strong empirical performance and ability to capture critical fraud‐risk factors from the inclearing dataset. Data rebalancing helped address low event frequency, and no distinct segmentation was applied. Feature selection and hyperparameter tuning were guided by Gains tables and AUC metrics, ensuring the final model offers robust detection power across a wide range of checks.

## 8.1. Summary of Model Implementation

The Inclearing Fraud Model V3 is implemented as part of the **Financial Crimes Non‐Card Transaction** fraud detection pipeline. It uses **PySpark** on **[CDSW / Spark cluster / internal big data platform]** to generate daily fraud scores for each inclearing transaction. These scores feed into the **Fraud Operations** rules engine, enabling real‐time or near‐real‐time alerts for potential fraudulent checks.

- **Application / System**:  
  - The model’s output is ingested into **Detica** (the downstream case management system), where Fraud Operations reviews high‐risk items.  
- **Code Platform and Prediction Flow**:  
  - The scoring code is stored in **[Bitbucket / GitHub / internal repository]**.  
  - During each production cycle, the pipeline reads inclearing transactions from the **Data Lake** (same as previous model version), applies the GBT model to compute a fraud likelihood score, and writes back the scored data to a **production table** for consumption by downstream applications.

Because the model architecture (a Gradient Boosted Classifier) and data ingestion pipeline are the same as in the previous version, minimal adjustments were needed beyond retraining on updated historical data.

## 8.2. Production Data Sources, Preparation, and Transformations

### 8.2.1. Data Pipeline

1. **Implementation/Prediction Pipeline**  
   - The system extracts daily inclearing transactions from **`dm_fraud_detection.inc_frd_<...>`** (or equivalent) within the Data Lake.  
   - A PySpark job transforms the raw data, applies feature engineering steps (similar to those used in model development), and feeds the resulting features into the GBT model object.  
   - The model scores each transaction, outputting the predicted probability of fraud (i.e., fraud score).

2. **Reference to Applicable Code**  
   - The Spark job is orchestrated via **[Airflow / internal scheduler]**.  
   - Code is tracked in **Bitbucket** under the repository **`<repo_name>`**, ensuring version control for any changes to data transformations.

### 8.2.2. Data Sources for Model Implementation

- **Inclearing Transaction Table** (`SB_FRAUD_NCA.incI_mth` or similar):  
  - Primary source of deposit items for scoring.  
  - Includes check amount, account details, transaction history, and other features.  
- **Supporting Tables** (internal to Regions):  
  - **SL1_DM, SL1_RF, SL1_DNCCR,** etc., used to enrich the transaction records with relationship, login, or case management attributes.  
- **Vendor Data (if applicable)**:  
  - As with the old model, no external vendor data is directly consumed at scoring time. All enhancements remain internal.

### 8.2.3. Weaknesses and Limitations in Source Data

- **Missing Fields or Records**:  
  - Rarely, certain checks may lack critical fields (e.g., no item serial number). As in the old model, these items receive partial scoring or default values.  
- **Infrequent Data Delays**:  
  - Overnight ingestion delays can occasionally cause a small subset of transactions to miss the day’s scoring window. They are captured and scored retroactively once the data is complete.

### 8.2.4. Data Appropriateness and Accuracy

The production data follows the same schema and cleaning rules as the development dataset, ensuring consistency. Periodic data audits confirm alignment between the development sample and live production feeds. If any outlier patterns emerge (e.g., new transaction codes), updates are made to the transformation logic to maintain model accuracy.

### 8.2.5. Handling Missing or Unknown Values

Any missing numeric fields continue to be imputed with **[–999 or 0, as appropriate]**, consistent with the approach taken during model training. Categoricals that are unrecognized or empty default to “unknown” categories. This approach has been retained from the old model to ensure consistent scoring behavior.

## 8.3. Production Environment

The production environment is hosted on **[CDSW / Hadoop Yarn / Spark cluster name]**, where the PySpark scoring pipeline executes on a daily schedule. The environment automatically pulls together the relevant data tables, runs feature transformations, and applies the GBT model. Key aspects:

1. **Data Integration & Model Execution**  
   - The daily job merges inclearing checks with relevant reference tables.  
   - The GBT scoring step runs after successful data ingestion, generating a **fraud score** per item.

2. **Rules and Overrides**  
   - The final fraud detection process relies on a combination of model output plus any business rules. For instance, certain high‐risk item types might be flagged regardless of model score.  
   - These overrides are the same ones used with the old model; they have been tested with the new GBT scores to confirm compatibility.

3. **Control / Production Checks**  
   - The pipeline logs each step’s status (extraction, transformation, scoring) to a monitoring dashboard.  
   - Reconciliation checks ensure that the number of rows scored matches the expected count of daily transactions.  
   - If errors occur, the pipeline triggers alerts to the Data & Analytics team to investigate and re‐run if necessary.

## 8.4. Model Output and Reporting

### 8.4.1. How Output Is Used and Weighed

The model outputs a numeric probability (fraud likelihood) for every check. Fraud Operations uses these scores to prioritize which items undergo a deeper investigation:

- **Score Thresholds**: If the predicted fraud likelihood exceeds certain cutoffs (e.g., top 5%), an alert is created in **Detica**.  
- **Further Processing**: No additional models consume the GBT output. The risk score is integrated directly into the existing rule engine for advanced decision logic.

### 8.4.2. Transmission and Automation Controls

Once daily scoring is complete, the resulting dataset (with final scores) is written to **[HDFS / a production table / object storage]**. Fraud Operations systems fetch these scores in near‐real time, applying them to:

- **Alerts**: An item with a high fraud score triggers an immediate alert for manual review.  
- **Reporting**: Summaries of daily alerts and captured fraud amounts are compiled in standard management reports.

### 8.4.3. Datasets Storing Model Results

- **Production Scored Table**: **`dm_fraud_detection.inc_frd_scored_v3`** (example naming) stores each check’s final features, the GBT score, and relevant metadata (date/time of scoring, system run ID, etc.).  
- **Historical Audit Dataset**: Archives older daily outputs, ensuring traceability for compliance and monitoring.

### 8.4.4. Disclaimers, Information, and Assumptions

- **Model Uncertainty**: The GBT score is a statistical estimate, not a definitive fraud/no‐fraud determination.  
- **Use of Imputed Values**: Missing data is imputed following the same scheme as training. This is highlighted in the model documentation to warn users that extremely missing data could reduce confidence in the score.  
- **Interpretation**: The final decision (to return or pay a check) remains the responsibility of Fraud Operations, guided by the model’s ranking but supplemented by domain expertise.

### 8.4.5. Controls and Reviews

- **Operational Reviews**: The business regularly reviews performance metrics (e.g., daily fraud capture, false positives) to ensure the model continues meeting goals.  
- **Committee Acceptance**: Any major changes to thresholds or the scoring pipeline are presented to the Model Risk Management committee for approval, maintaining governance standards.

---

**In summary**, the **Model Implementation** for Version 3 follows the same robust pipeline and operational framework as its predecessor. It leverages existing data sources, transformations, and rule sets—requiring only minimal adjustments to accommodate the newly trained GBT model. This consistent design ensures minimal disruption while introducing improved fraud detection capability.
